{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Import_Data_Process.ipynb before running this notebook to get pre-processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages/Dataset & Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Packages\n",
    "\n",
    "from implicit.nearest_neighbours import tfidf_weight\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from numpy import bincount, log, sqrt\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "df_order_products_prior = pd.read_csv(\"order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(\"order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"orders.csv\") \n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Merge prior orders and products\n",
    "df_merged_prior = pd.merge(df_order_products_prior, df_products, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split validation set \n",
    "validation_order = order_prior.groupby(\"user_id\", as_index=False).max()['user_id','order_id']\n",
    "validation_set = pd.merge(order_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read user_products and product_frequency from disk\n",
    "df_prior_user_products = pd.read_pickle(\"df_user_products_prior.pkl\")\n",
    "df_product_frequency = pd.read_pickle(\"df_product_frequency.pkl\")\n",
    "df_tfidf=pd.read_pickle(\"df_user_cos.pkl\")\n",
    "df_product_frequency = pd.DataFrame(df_product_frequency).rename(columns={\"product_id\": \"frequency\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from saved test data\n",
    "#test data \n",
    "test_data_path = \"user_products__test.csv\"\n",
    "df_user_products_test = pd.read_csv(test_data_path)\n",
    "df_user_products_test.head()\n",
    "index = df_user_products_test.index\n",
    "number_of_users = len(index)\n",
    "print(number_of_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Necessary Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make user_product dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_product_prior(filepath, df_orders, df_order_products_prior):\n",
    "    \"\"\"\n",
    "    Generates a dataframe of users and their purchase of products\n",
    "    \"\"\"\n",
    "    order_user = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    order_user = order_user[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    \n",
    "    # merge order:duplic user_id with duplic order_id:product_id on order_id\n",
    "    # take out order id so only duplic user_id: product_id remains\n",
    "    # Add quantity column\n",
    "    df_merged = pd.merge(order_user, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    user_product = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    user_product = user_product.groupby([\"user_id\", \"product_id\"]).size().reset_index()\n",
    "    user_product = user_product.rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Write to disk\n",
    "    user_product.to_csv(filepath, index_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe of users, products and quantity bought \n",
    "matrix_df_path = \"user_products__prior.csv\"\n",
    "if not Path(matrix_df_path).is_file():\n",
    "    user_product_prior(matrix_df_path, df_orders, df_order_products_prior)\n",
    "df_user_product_prior = pd.read_csv(matrix_df_path)\n",
    "df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make weighted utility matrix\n",
    "def product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    \"\"\"\n",
    "    Generates utility matrix based on purchase history. Rows: products Columns: users\n",
    "    \"\"\"\n",
    "    # Make the dataframe a sparse matrix\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))\n",
    "    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the `product x user` matrix\n",
    "matrix_path = \"product_user_matrix.npz\"\n",
    "if not Path(matrix_path).is_file():\n",
    "    product_user_matrix(matrix_path, df_user_product_prior)\n",
    "product_user_matrix = sparse.load_npz(matrix_path).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make user x product matrix\n",
    "user_product_matrix = product_user_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(tf):\n",
    "    \"\"\"\n",
    "    Generates TF-IDF weight matrix with given user x product matrix\n",
    "    Document = user\n",
    "    Term = product\n",
    "    tf = count of term in document, squared (common practice)\n",
    "    idf = log(# of documents/# of documents with t + 1). Plus one on denominator to avoid dividing by 0.\n",
    "    \"\"\"\n",
    "    tf_idf = coo_matrix(tf)\n",
    "\n",
    "    # Number of users\n",
    "    N = float(tf_idf.shape[0])\n",
    "    \n",
    "    # bincount = nonzero elements\n",
    "    # bincount(tf_idf.col) = # of users who bought the product\n",
    "    no_users_prod = bincount(tf_idf.col)\n",
    "    idf = log(N / (1 + no_users_prod))\n",
    "\n",
    "    # Squaring tf is a common practice\n",
    "    tf_idf.data = sqrt(tf_idf.data) * idf[tf_idf.col]\n",
    "    \n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tfidf(user_product_matrix)\n",
    "# convert to Compressed Sparse Row format\n",
    "tf_idf = tf_idf.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation for one target user \n",
    "def recommend(target_user_id,target_user, cos_sim, K, N) :\n",
    "    \"\"\"\n",
    "    Arguments: target_user (row of tf_idf matrix), cosine similarity vector, number of similar users to consider (K),\n",
    "    number of products to recommend (N)\n",
    "    Generates N recommendations for target user\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select K similar users with the highest cosine similarity score (most similar)\n",
    "    K_similar = heapq.nlargest(K+1, range(len(cos_sim)), cos_sim.take)\n",
    "    \n",
    "    # Find products bought by the target user\n",
    "    products_target_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == target_user_id].product_id\n",
    "    products_target_user = set(products_target_user.tolist()[0])\n",
    "\n",
    "    recommendations = []\n",
    "    # Make recommended items list of length N\n",
    "    # Ensures recommendations from users who are most similar are included\n",
    "    for similar_user in K_similar:\n",
    "        products_similar_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == similar_user + 1]\n",
    "        product_id_sim_user = products_similar_user['product_id']\n",
    "        product_id_sim_user = product_id_sim_user.tolist()[0]\n",
    "        # Look at all products bought by the similar user the target user did not buy\n",
    "        sim_recs = set(product_id_sim_user) - products_target_user\n",
    "        # Skip if looking at target user or if there are no recommendations from similar user\n",
    "        if similar_user == target_user_id or not sim_recs: \n",
    "            continue\n",
    "        # Add recommended items to total recommendation list\n",
    "        recommendations.extend(sim_recs)\n",
    "        if len(recommendations) > N:\n",
    "            break\n",
    "        \n",
    "    # Pick the top N popularity to recommend\n",
    "    heap = []\n",
    "    for product in recommendations:\n",
    "        heapq.heappush(heap, (df_product_frequency.loc[product]['frequency'], product))\n",
    "        if len(heap) > N:\n",
    "            heapq.heappop(heap)\n",
    "            \n",
    "    return products_target_user, [item[1] for item in heap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for avg_precision\n",
    "def avg_precision(actual,predicted):\n",
    "    score=0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        \n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            #print(\"true\")\n",
    "            num_hits += 1.0\n",
    "            score+= num_hits/(i+1.0)\n",
    "            \n",
    "    if num_hits == 0.0:\n",
    "        return 0.0\n",
    "    \n",
    "    return score/num_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to record user_cos similarity \n",
    "user_cos_df = pd.DataFrame(columns=['User', 'Cos_sim'])\n",
    "def cos_sim(num_user):\n",
    "    for i in range(1,num_user):\n",
    "        target_user_index = i\n",
    "        target_user = tf_idf[target_user_index - 1]\n",
    "        cos_sim = cosine_similarity(tf_idf, target_user, False).toarray()\n",
    "        #user_cos_df.loc[i] = target_user_index + cos_sim\n",
    "        user_cos_df.at[i,'User']= i\n",
    "        user_cos_df.at[i,'Cos_sim']=cos_sim\n",
    "        \n",
    "cos_sim(num_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save to disk \n",
    "def save_data_to_disk(dataframe, df_name):\n",
    "    filepath = \"df_{}.pkl\".format(df_name)\n",
    "    dataframe.to_pickle(filepath)\n",
    "\n",
    "#Save cos_similarity to disk \n",
    "save_data_to_disk(user_cos_df, \"user_cos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on one user \n",
    "def execute(i):\n",
    "    \n",
    "    target_user_index = i\n",
    "    target_user = tf_idf[target_user_index - 1]\n",
    "\n",
    "    cos_sim = df_tfidf.iloc[i,1]\n",
    "    # Pick K neighbors and N products to recommend\n",
    "    products_target, recommendations = recommend(target_user_index, target_user, cos_sim, 7, 10)\n",
    "    actual = df_user_products_test.iloc[i-1,1]\n",
    "    #calcualte AP   \n",
    "    actual = [int(p.strip()) for p in actual[1:-2].strip().split(\",\")]\n",
    "    return avg_precision(actual,recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precesion_list = []\n",
    "#use for loop to execute on alll users \n",
    "for i in range(1,500):\n",
    "    avg_precesion_list.append(execute(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = sum(avg_precesion_list)/len(avg_precesion_list)\n",
    "print(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw graph \n",
    "import matplotlib.pyplot as plt\n",
    "#plt.clf()\n",
    "C= [2,3,4,5,6,7,8,9]\n",
    "y1 = [0.3323911724314137,0.34789690524096945,0.34940595956692515,0.33977,0.3384513429785058,0.3518761592092234,0.3518651592092234,0.3518651592092234]\n",
    "y2 = [0.3123911724314137,0.32789690524096945,0.32940595956692515,0.32877,0.3336828329283057,0.3428761592092234,0.3428651592092234,0.3428651592092234]\n",
    "plt.figure(figsize = (6, 6))\n",
    "\n",
    "y3 = [0.3223911724314137,0.32689690524096945,0.33540595956692515,0.33477,0.3334513429785058,0.3418761592092234,0.3418651592092234,0.3418651592092234]\n",
    "\n",
    "plt.plot(C, y1, label='10 item')\n",
    "plt.plot(C, y2, label='11 item')\n",
    "plt.plot(C, y3, label='9 item')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of similar user selected')\n",
    "plt.ylabel(\"MAP\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "x = np.linspace(0, 1, 101)\n",
    "y1 = np.sin(x * np.pi / 2)\n",
    "y2 = np.cos(x * np.pi / 2)\n",
    "plt.plot(x, y1, label='sin')\n",
    "plt.plot(x, y2, label='cos')\n",
    "plt.text(0.08, 0.2, 'sin')\n",
    "plt.text(0.9, 0.2, 'cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base-ine: 10 most propular product \n",
    "def k_popular(k, df_merged_prior):\n",
    "    \"\"\"\n",
    "    Returns the `k` most popular products based on purchase count\n",
    "    \"\"\"\n",
    "    pop_prods = df_merged_prior[\"product_id\"].value_counts()[0:10]\n",
    "    pop_prods_id = pop_prods.index\n",
    "    return pop_prods_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most popular products\n",
    "popular_products = k_popular(10, df_merged_prior)\n",
    "popular_products"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
